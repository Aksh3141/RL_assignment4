Environment: InvertedPendulum-v4
Algorithm: PPO
Run name: PPO_InvPend
Total timesteps: 500000

===== EVALUATION =====
Mean Reward: 1000.0
Std Reward : 0.0

===== HYPERPARAMETERS USED =====
algorithm: PPO
total_timesteps: 500000
log_interval: 200
eval_freq: 5000
save_freq: 20000
Run_name: PPO_InvPend
learning_rate: 0.0003
n_steps: 2048
batch_size: 64
n_epochs: 10
gamma: 0.99
gae_lambda: 0.95
clip_range: 0.2
ent_coef: 0.0
vf_coef: 0.5
max_grad_norm: 0.5
policy_kwargs: {'net_arch': [{'pi': [64, 64], 'vf': [64, 64]}]}

Model saved at: logs/PPO/InvertedPendulum-v4/PPO_InvPend/models/final_model.zip
GIF saved at  : logs/PPO/InvertedPendulum-v4/PPO_InvPend/PPO_InvertedPendulum-v4_eval.gif
